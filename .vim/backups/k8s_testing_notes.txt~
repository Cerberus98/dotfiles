# Make the ISO:
make_iso rhel-atomic-installer-7.3.2-1.x86_64.iso config-vagrant.yaml

# Make a landing place for the tar
mkdir ~/derp
cd ~/derp

# Tar the file to OSX:
ssh vagrant@192.168.33.10 "tar czvf - /tmp/tmp48Zo_E" | pv | tar xzf -

# copy all vagrant files into the local dir
cp ~/code/python/sparta/vagrant/* .

# rename some stuff
mv vagrant-config.yaml.example vagrant-config.yaml
mv rhel-atomic-installer-7.3.2-1.x86_64.iso rhel-atomic-unattended-7.3.2-1.x86_64.iso

# You may need to ensure that paranoid is false (to turn off host key checking)
# and similarly, you may need to have it use a personal SSH key explicitly

# ... in Vagrantfile ...
config.ssh.paranoid = false
config.ssh.private_key_path = "~/.ssh/id_rsa"
# We also need to set up port forwards to 8001, 8080, 8899, 9090 here
ESC :wq

# Alternatively, this might work in ~/.vagrant.d/Vagrantfile
Vagrant.configure('2') do |config|
  config.ssh.paranoid = false
  config.ssh.private_key_path = "~/.ssh/id_rsa"
end

# Bring up vagrant
vagrant up

# Wait forever and then SSH in
while true; do ssh admin@127.0.0.1 -p2222; sleep 5; done

# Install the dashboard
curl https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml > kubernetes-dashboard.yml
nano kubernetes-daseboard.yaml
# Find the line --apiserver-host, uncomment, and set to the hostNetwork IP of the API server
# It looks like we need to stand up some kind of local DNS that let's the dashboard find things on it's own. Are we missing k8s service discovery?

- --apiserver-host http://10.15.15.2:8080
# Additionally, add this under "containers" at the same indentation depth as "containers". The default container network doesn't have a route to the host network,
# and our containers are currently on said hostnetwork. https://kubernetes.io/docs/user-guide/config-best-practices/ Apparently this is an incorrect line of
# thought and we need to address it.
hostNetwork: true

# Save and quit

# Fix this later
# kubectl create -f https://rawgit.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml

# On node0. This forwards connects to pods. Make sure to set up a Vagrant forward to 8001:8001
kubectl proxy --address 0.0.0.0

# Start helm. If you do the port forwarding right, helm init works. However, like the dash, it blows up because everything else is on the host network
helm init

# Instead, for now:
helm init --dry-run --debug > tiller.yaml

# Fix it as per here:
https://metacloud.jira.com/wiki/spaces/HARMONY/pages/187178379/Helm+Tiller+Workflow

# Except this doesn't work and I don't know why KUBERNETES_MASTER is 10.10.20.100:8080 because that ain't right.
# Set it to 10.15.15.2:8080 instead

# Run it this way
ubectl create -f helm-manifest.yaml

# Getting pod information
kubectl describe pods tiller-deploy -n kube-system

# Get pod logs
kubectl logs tiller-deploy-3655218845-3qcm0 -n kube-system

# When it breaks
kubectl delete pods,services,deployments tiller-deploy --namespace kube-system

# Clone kolla-k8s and set it up
git clone git@github.com:openstack/kolla-kubernetes.git
mkvirtualenv kolla-k8s
cd kolla-kubernetes
pip install -r requirements.txt
pip install -e .
